<!DOCTYPE html>
<html>
<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-172831425-1"></script>
	<script>
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());

	gtag('config', 'UA-172831425-1');
	</script>

	<meta content="en-us" http-equiv="Content-Language">
	<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
	<title>Ziyi Wu - UofT</title>
	<meta charset="utf-8">
	
	<style type="text/css">
		.container {
			zoom: 1;
			margin-left: auto;
			margin-right: auto;
			vertical-align: middle;
			text-align: left;
			width: 100%;
			max-width: 800px;
		}

		a {text-decoration:none}
		a:any-link{color: royalblue;}
		a:link{color:royalblue;}
		a:visited{color:royalblue;}
		a:hover{color:blue;}
	</style>
</head>
<body><div class="container">
	<table border="0" id="table1" width="720">
		<tbody>
			<tr>
				<td width="400">
					<p align="center"><font face="Arial"><img border="0" src="imgs/me.jpg" height="224"></font></p>
				</td>
				<td>
					<font face="Arial" size="6"><b>&nbsp;Ziyi Wu <span lang="zh-cn">(吴紫屹)</span></b></font>
					<p><font face="Arial" style="font-size: 12pt;">&nbsp; Ph.D. Student</font></p>
					<p><font face="Arial" style="font-size: 12pt;">&nbsp; University of Toronto</font></p>
					<p><font face="Arial" style="font-size: 12pt;">&nbsp; Email: ziyiwu [at] cs.toronto.edu</font></p>
					&nbsp; <a href="files/CV.pdf">CV</a> &bull; <a href="https://scholar.google.com/citations?user=iopH6wIAAAAJ&hl=en&oi=ao">Google Scholar</a> &bull; <a href="https://github.com/Wuziyi616">GitHub</a> &bull; <a href="https://twitter.com/Dazitu_616">Twitter</a>
				</td>
			</tr>
		</tbody>
	</table>

	<p><b><font face="Times New Roman" size="5">
		About
	</font></b></p>
	<table border="1" style="border-width: 0px;" width="800">
		<tbody>
			<tr>
				<td style="border-style: none; border-width: medium;">
					<p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;"><font face="Arial" style="font-size: 12pt;">
					I am a fourth-year PhD student in <a href="https://tisl.cs.utoronto.ca/">Toronto Intelligent Systems Lab (TISL)</a> at the University of Toronto and affiliated with the <a href="https://vectorinstitute.ai/">Vector Institute</a>.
					My advisor is Prof. <a href="https://tisl.cs.utoronto.ca/author/igor-gilitschenski/">Igor Gilitschenski</a>.
					I am currently an intern at Snap research working with Dr. <a href="https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/">Aliaksandr Siarohin</a> and Dr. <a href="https://stulyakov.com/">Sergey Tulyakov</a>.
					<!-- I had the fortune to work with Prof. <a href="https://animesh.garg.tech/">Animesh Garg</a>, Prof. <a href="https://taiya.github.io/">Andrea Tagliasacchi</a>. -->
					I was a Student Researcher at Google DeepMind with Dr. <a href="https://tkipf.github.io/">Thomas Kipf</a> in Spring 2024.
					<br><br>
					Prior to my Ph.D., I received my Bachelor's degree from the Department of Automation, Tsinghua University, where I worked with Prof. <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Jiwen Lu</a>.
					I spent an unforgettable summer in 2020 doing internship at Stanford University, advised by Prof. <a href="https://geometry.stanford.edu/member/guibas/index.html">Leonidas J. Guibas</a>.
					<br><br>
					I am broadly interested in designing machine learning systems that can perceive the world as we humans do, which I believe is the cornerstone of achieving AGI.
					Recently, I am working on generative AI (world models) and object-centric learning (structured representation).
					<!-- I have been working on generative AI (world models), object-centric learning (structured representation), and <a href="https://en.wikipedia.org/wiki/Event_camera">event-based vision</a> (silicon retina). -->
				</font></p><font face="Arial" style="font-size: 12pt;"></font>
				</td>
			</tr>
		</tbody>
	</table>

	<p><b><font face="Times New Roman" size="5"><br>
		News
	</font></b></p>
		<font face="Arial" style="font-size: 12pt; line-height: 2;">
		<ul>
			<li><b style="color: green; background-color: #ffff42">NEW</b> [Jan, 2025] SG-I2V is accepted by <b>ICLR 2025</b>!</li>
			<li> [Jan, 2025] Invited talk at <a href="https://vectorinstitute.ai/">Vector Institute</a> on Neural Assets.</li>
			<li> [Dec, 2024] We release MinT, a time-controlled multi-event video generator!</li>
			<li> [Sept, 2024] Neural Assets is accepted by <b>NeurIPS 2024</b> as a Spotlight Presentation!</li>
			<!-- <li> [Jun, 2024] I start my internship at Snap working with Dr. <a href="https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/">Aliaksandr Siarohin</a>!</li> -->
			<li> [Feb, 2024] Two papers on multi-view diffusion model and event camera are accepted by <b>CVPR 2024</b>!</li>
			<!-- <li> [Dec, 2023] I start my Student Researcher position at Google DeepMind working with Dr. <a href="https://tkipf.github.io/">Thomas Kipf</a>!</li> -->
			<li> [Sept, 2023] SlotDiffusion is accepted by <b>NeurIPS 2023</b> as a Spotlight Presentation!</li>
			<li> [Feb, 2023] Two invited talk on SlotFormer in Prof. <a href="https://www.andrew.cmu.edu/user/kunz1/index.html">Kun Zhang</a>'s group and <a href="https://ni.www.techfak.uni-bielefeld.de/">Neuroinformatics Group</a>. Thanks <a href="https://scholar.google.com/citations?user=6tiiQtgAAAAJ&hl=en">Andrew</a> and <a href="https://chengy12.github.io/">Guangyi</a> for inviting me!</li>
			<li> [Jan, 2023] SlotFormer is accepted by <b>ICLR 2023</b>!</li>
			<li> [Oct, 2022] SlotFormer won 1st place at <b>ECCV 2022 MVCS Workshop</b> CLEVRER Challenge!</li>
			<!-- <li> [Sept, 2022] Breaking Bad is accepted by <b>NeurIPS 2022 Datasets Track</b> as a Featured Presentation!</li> -->
			<!-- <li> [July, 2021] One paper accepted by <b>ICCV 2021</b>!</li> -->
			<!-- <li> [June, 2021] I graduated with first-class honor from Tsinghua University.</li> -->
			<!-- <li> [Spring, 2021] Wonderful internship at <a href="https://www.sensetime.com/en">SenseTime</a> developing <a href="https://github.com/open-mmlab/mmdetection3d">MMDetection3D</a>: <a href="https://github.com/open-mmlab/mmdetection3d"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/open-mmlab/mmdetection3d?style=social"></a> mentored by Dr. <a href="http://chenkai.site/">Kai Chen</a> and <a href="http://zhangwenwei.cn/">Wenwei Zhang</a>.</li> -->
			<!-- <li> [Jan, 2021] One paper accepted by <b>T-PAMI</b>!</li> -->
			<!-- <li> [Dec, 2020] Invited talk about my research on 3D point cloud adversarial attack and defense in Prof. <a href="http://www.cs.toronto.edu/~urtasun/">Raquel Urtasun</a>'s group.</li> -->
			<!-- <li> [Dec, 2020] I am awarded the <b>SenseTime Scholarship 2020</b>.</li> -->
			<!-- <li> [Mar, 2020] One paper accepted by <b>CVPR 2020</b>!</li> -->
		</ul>
		</font>

	<p><b><font face="Times New Roman" size="5"><br>
		Research
	</font></b></p>
	* indicates equal contribution/supervision

	<p><b><font face="Times New Roman" size="4"><br>
		Preprints
	</font></b></p>
	<table width="1000">
		<!--MinT-->
		<tbody><tr>
			<td width="30%" valign="middle"><p><img src="./imgs/mint.gif" width="280" alt="S2Edit" style="border-style: none" align="top"></p></td>
			<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
				<b>Mind the Time: Temporally-Controlled Multi-Event Video Generation</b><br>
					<strong>Ziyi Wu</strong>, Aliaksandr Siarohin, Willi Menapace, Ivan Skorokhodov,<br>
					Yuwei Fang, Varnith Chordia, Igor Gilitschenski*, Sergey Tulyakov*<br>
				<em>arXiv 2024</em>.<br>
				[<a href="https://mint-video.github.io/">Project Page</a>]
			</p></td></tr>
		</tbody>
	</table>

	<p><b><font face="Times New Roman" size="4"><br>
		Publications
	</font></b></p>
	<table width="1000">
		<!--SG-I2V-->
		<tbody><tr>
			<td width="30%" valign="middle"><p><img src="./imgs/sg-i2v.gif" width="280" alt="S2Edit" style="border-style: none" align="top"></p></td>
			<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
				<b>SG-I2V: Self-Guided Trajectory Control in Image-to-Video Generation</b><br>
					Koichi Namekata, Sherwin Bahmani, <strong>Ziyi Wu</strong>, Yash Kant,<br>
					Igor Gilitschenski, David B. Lindell<br>
				<em>ICLR 2025</em>.<br>
				[<a href="https://kmcode1.github.io/Projects/SG-I2V/">Project Page (with paper and code)</a>]
			</p></td></tr>
		</tbody>

		<!--Neural Assets-->
		<tbody><tr>
			<td width="30%" valign="middle"><p><img src="./imgs/neural_assets.gif" width="280" alt="S2Edit" style="border-style: none" align="top"></p></td>
			<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
				<b>Neural Assets: 3D-Aware Multi-Object Scene Synthesis with Image Diffusion Models</b><br>
					<strong>Ziyi Wu</strong>, Yulia Rubanova, Rishabh Kabra, Drew A. Hudson, Igor Gilitschenski,<br>
					Yusuf Aytar, Sjoerd van Steenkiste, Kelsey Allen, Thomas Kipf<br>
				<em>NeurIPS 2024</em>.<br>
				<b style="color:red">Spotlight Presentation</b><br>
				[<a href="https://neural-assets.github.io/">Project Page</a>]
			</p></td></tr>
		</tbody>

		<!--SPAD-->
		<tbody><tr>
			<td width="30%" valign="middle"><p><img src="./imgs/spad.gif" width="280" alt="SPAD" style="border-style: none" align="top"></p></td>
			<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
				<b>SPAD: Spatially Aware Multiview Diffusers</b><br>
					Yash Kant, <strong>Ziyi Wu</strong>, Michael Vasilkovsky, Guocheng Qian, Jian Ren, Riza Alp Guler,<br>
					Bernard Ghanem, Sergey Tulyakov*, Igor Gilitschenski*, Aliaksandr Siarohin*<br>
				<em>CVPR 2024</em>.<br>
			[<a href="https://yashkant.github.io/spad/">Project Page (with paper, code, and slides)</a>]
			</p></td></tr>
		</tbody>

		<!--LEOD-->
		<tbody><tr>
			<td width="30%" valign="middle"><p><img src="./imgs/leod-results.gif" width="280" alt="LEOD" style="border-style: none" align="top"></p></td>
			<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
				<b>LEOD: Label-Efficient Object Detection for Event Cameras</b><br>
					<strong>Ziyi Wu</strong>, Mathias Gehrig, Qing Lyu, Xudong Liu, Igor Gilitschenski<br>
				<em>CVPR 2024</em>.<br>
			[<a href="https://arxiv.org/abs/2311.17286">Paper</a>]&nbsp;
			[<a href="https://github.com/Wuziyi616/LEOD">Code</a>]&nbsp;
			[<a href="files/LEOD.pptx">Slides</a>]
			</p></td></tr>
		</tbody>

		<!--SlotDiffusion-->
		<tbody><tr>
			<td width="30%" valign="middle"><p><img src="./imgs/slotdiffusion-results.png" width="280" alt="SlotDiffusion" style="border-style: none" align="top"></p></td>
			<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
				<b>SlotDiffusion: Object-Centric Generative Modeling with Diffusion Models</b><br>
					<strong>Ziyi Wu</strong>, Jingyu Hu*, Wuyue Lu*, Igor Gilitschenski, Animesh Garg<br>
				<em>NeurIPS 2023 | ICLR@NeSy-GeMs workshop, 2023</em>.<br>
				<b style="color:red">Spotlight Presentation</b><br>
				[<a href="https://slotdiffusion.github.io/">Project Page (with paper and code)</a>]&nbsp;
				[<a href="files/SlotDiffusion.pptx">Slides</a>]
			</p></td></tr>
		</tbody>

		<!--SlotFormer-->
		<tbody><tr>
			<td width="30%" valign="middle"><p><img src="./imgs/slotformer-results.gif" width="280" alt="SlotFormer" style="border-style: none" align="top"></p></td>
			<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
				<b>SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric Models</b><br>
					<strong>Ziyi Wu</strong>, Nikita Dvornik, Klaus Greff, Thomas Kipf*, Animesh Garg*<br>
				<em>ICLR 2023 | UAI@CRL workshop, 2022 | ECCV@MVCS Challenge, 2022</em>.<br>
			[<a href="https://slotformer.github.io/">Project Page (with paper and code)</a>]&nbsp;
			[<a href="files/SlotFormer.pptx">Slides</a>]
			</p></td></tr>
		</tbody>

		<!--Breaking Bad Dataset-->
		<tbody><tr>
			<td width="30%" valign="middle"><p><img src="./imgs/breaking-bad.png" width="280" alt="Breaking Bad" style="border-style: none" align="top"></p></td>
			<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
				<b>Breaking Bad: A Dataset for Geometric Fracture and Reassembly</b><br>
					Silvia Sellán*, Yun-Chun Chen*, <strong>Ziyi Wu*</strong>, Animesh Garg, Alec Jacobson<br>
				<em>NeurIPS 2022 Datasets and Benchmarks Track</em>.<br>
				<b style="color:red">Featured Paper Presentation</b><br>
			[<a href="https://breaking-bad-dataset.github.io/">Project Page (with paper, code, and data)</a>]&nbsp;
			[<a href="files/BiDet.pptx">Slides</a>]
			</p></td></tr>
		</tbody>

		<!--ISL-->
		<tbody><tr>
			<td width="30%" valign="middle"><p><img src="./imgs/ISL.png" width="270" alt="ISL" style="border-style: none" align="top"></p></td>
			<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
				<b>Instance Similarity Learning for Unsupervised Feature Representation</b><br>
					Ziwei Wang, Yunsong Wang, <strong>Ziyi Wu</strong>, Jiwen Lu, Jie Zhou<br>
				<em>ICCV 2021</em>.<br>
			[<a href="https://arxiv.org/abs/2108.02721">Paper</a>]&nbsp;
			[<a href="https://github.com/ZiweiWangTHU/ISL">Code</a>]
			</p></td></tr>
		</tbody>

		<!--AutoBiDet-->
		<tbody><tr>
			<td width="30%" valign="middle"><p><img src="./imgs/autobidet.png" width="270" alt="AutoBiDet" style="border-style: none" align="top"></p></td>
			<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
				<b>Learning Efficient Binarized Object Detectors with Information Compression</b><br>
					Ziwei Wang, Jiwen Lu, <strong>Ziyi Wu</strong>, Jie Zhou<br>
				<em>T-PAMI 2021</em>.<br>
			[<a href="https://ieeexplore.ieee.org/document/9319565">Paper</a>]
			</p></td></tr>
		</tbody>

		<!--BiDet-->
		<tbody><tr>
			<td width="30%" valign="middle"><p><img src="./imgs/bidet.png" width="270" alt="BiDet" style="border-style: none" align="top"></p></td>
			<td width="70%" valign="middle"><p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;">
				<strong>BiDet: An Efficient Binarized Object Detector</strong><br>
					Ziwei Wang, <strong>Ziyi Wu</strong>, Jiwen Lu, Jie Zhou<br>
				<em>CVPR 2020</em>.<br>
			[<a href="https://arxiv.org/abs/2003.03961">Paper</a>]&nbsp;
			[<a href="https://github.com/ZiweiWangTHU/BiDet">Code</a>]&nbsp;
			[<a href="files/BiDet.pptx">Slides</a>]
			</p></td></tr>
		</tbody>
	</table>

	<p><b><font face="Times New Roman" size="5"><br>
		Academic Services</font></b></p>
		<table border="1" style="border-width: 0px;" width="900">
			<tbody>
				<tr>
					<td style="border-style: none; border-width: medium;">
						<p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;"><font face="Arial" style="font-size: 11pt;">
							Journal reviewer: T-PAMI; TMLR; ISRR; RA-L;<br>
							Conference reviewer: CVPR'22-25; ICCV'23; ECCV'22-24; NeurIPS'22-24; ICML'23-25; ICLR'24-25; AAAI'23-24; IJCAI'24; IROS'22; ICRA'23-24;<br>
							Workshop reviewer: OSC@ICLR'22;
						</font></p><font face="Arial" style="font-size: 11pt;"></font>
					</td>
				</tr>
			</tbody>
		</table><br>

		<p><b><font face="Times New Roman" size="5"><br>
			Teaching</font></b></p>
			<table border="1" style="border-width: 0px;" width="900">
				<tbody>
					<tr>
						<td style="border-style: none; border-width: medium;">
							<p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;"><font face="Arial" style="font-size: 11pt;">
								Teaching Assistant, <a href="https://uoft-isl.github.io/csc478-w23/">CSC 478: Robotics Perception</a><span style="float:right;">23 Winter</span><br>
								Teaching Assistant, CSC 108: Introduction to Computer Programming<span style="float:right;">21 Fall, 22 Winter, 22 Fall, 23 Summer</span>
						</font></p><font face="Arial" style="font-size: 11pt;"></font>
						</td>
					</tr>
				</tbody>
			</table><br>

	<p><b><font face="Times New Roman" size="5"><br>
		Selected Awards</font></b></p>
		<font face="Arial" style="font-size: 12pt; line-height: 2;">
			<ul>
				<li><strong>Outstanding reviewer at NeurIPS, 2024.</strong></li>
				<li><strong>Outstanding reviewer at NeurIPS, 2023.</strong></li>
				<li><strong>1st place in CLEVRER track at <a href="https://mvcs-workshop.github.io/">MVCS Challenge</a> (ECCV 2022 Workshop), 2022.</strong></li>
				<li>Outstanding Graduates (Beijing, Tsinghua University & Dept. of Automation), 2021.</li>
				<li><strong><a href="https://www.sensetime.com/en">SenseTime</a> Undergraduate Scholarship for AI Research, 2020.</strong></li>
				<li><a href="https://www.mi.com/global/">Xiaomi</a> Scholarship, Tsinghua University, 2020.</li>
				<li>Fang Chongzhi Scholarship, Tsinghua University, 2019.</li>
				<li><strong>Chinese National Scholarship, 2018.</strong></li>
				<li>Spark Program Membership, Tsinghua University.</li>
			</ul>
		</font>

	<p><b><font face="Times New Roman" size="5"><br>
		Miscellaneous</font></b></p>
		<table border="1" style="border-width: 0px;" width="900">
			<tbody>
				<tr>
					<td style="border-style: none; border-width: medium;">
						<p style="margin-top: 3px; margin-bottom: 3px; line-height: 1.25;"><font face="Arial" style="font-size: 11pt;">
						I like basketball and soccer. My favorite players are <a href="https://en.wikipedia.org/wiki/LeBron_James"><strong>LeBron James</strong></a> (well, associate G.O.A.T.?) and <a href="https://en.wikipedia.org/wiki/Lionel_Messi"><strong>Lionel Messi</strong></a> (real G.O.A.T.!).
						<br><br>
						I love reading (especially when I am stuck in research). My favorite books are <a href="https://en.wikipedia.org/wiki/One_Hundred_Years_of_Solitude">One Hundred Years of Solitude</a>, <a href="https://en.wikipedia.org/wiki/Nineteen_Eighty-Four">1984</a>, <a href="https://en.wikipedia.org/wiki/The_Plague_(novel)">The Plague</a>, <a href="https://en.wikipedia.org/wiki/The_World_of_Yesterday">The World of Yesterday</a> (added, 2024.1), and <a href="https://en.wikipedia.org/wiki/Dream_of_the_Red_Chamber">Dream of the Red Chamber</a> (红楼梦). Some of my recent (since 2021) favorites are <a href="https://en.wikipedia.org/wiki/Hannah_Arendt">Hannah Arendt</a>, <a href="https://en.wikipedia.org/wiki/Hermann_Hesse">Hermann Hesse</a>, <a href="https://en.wikipedia.org/wiki/Milan_Kundera">Milan Kundera</a>, <del><a href="https://en.wikipedia.org/wiki/Mo_Yan">Mo Yan</a></del> (莫言), <del><a href="https://en.wikipedia.org/wiki/Alexis_de_Tocqueville">Tocqueville</a></del>, <del><a href="https://en.wikipedia.org/wiki/Yasunari_Kawabata">Yasunari Kawabata</a></del>, <del><a href="https://en.wikipedia.org/wiki/Marcel_Proust">Proust</a></del>, etc. My main interests are ethics, human nature and values.
						<br><br>
						I am also an Anime fan and a lover of Visual Novel, and JRPG (added, 2023.1). Some of my favorite works are <a href="https://en.wikipedia.org/wiki/Fate/stay_night"><i>Fate/Stay Night</i></a>, <a href="https://en.wikipedia.org/wiki/Neon_Genesis_Evangelion_(franchise)"><i>EVA</i></a>, <a href="https://en.wikipedia.org/wiki/Perfect_Blue"><i>Perfect Blue</i></a>, <a href="https://en.wikipedia.org/wiki/Hyouka"><i>Hyouka</i></a>, <a href="https://en.wikipedia.org/wiki/Wonderful_Everyday"><i>Subarashiki Hibi</i></a> (a.k.a. Wonderful Everyday), and <a href="https://en.wikipedia.org/wiki/Persona_5">Persona 5</a> (added, 2023.1).
						<br><br>
						Two persons I admire the most: <a href="http://kaiminghe.com/"><strong>Kaiming He</strong></a> for his outstanding research tastes (<em>"All great truths are simple in final analysis"</em>) and <a href="https://en.wikipedia.org/wiki/Elon_Musk"><strong>Elon Musk</strong></a> for his aspiration and enthusiasm (now in doubt, 2022.12. <em>"Power tends to corrupt and absolute power corrupts absolutely"</em>).
						<br><br>
						I write an article (in Chinese) summarizing the experience during my CS PhD application process. Take a look <a href="https://zhuanlan.zhihu.com/p/350439006">here</a>!
					</font></p><font face="Arial" style="font-size: 11pt;"></font>
					</td>
				</tr>
			</tbody>
		</table><br>

		<div style="margin:10px auto;height: 270px; pointer-events: none;">
			<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=500&t=tt&d=x0OH_adH2t_SCrC7Z9P2mQ-27rJ6L2XAo0D_WJl6pEU'></script>
		</div>
	<br>

	<hr>
	<font style="font-size:10">Ziyi Wu <i>Last updated: Feb.4, 2025</i></font>

</div></body>
